{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a462d3ccc3b42dbae35c7539d82b3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dac5344f25b46c99c95e50ea3f1fdf2",
              "IPY_MODEL_0c6a41b79c9e41d9afc4379002c37b17",
              "IPY_MODEL_8588ff4af8b14fba956955babe0f4325"
            ],
            "layout": "IPY_MODEL_bcf44cc6baec464088cf2071ded9a30f"
          }
        },
        "0dac5344f25b46c99c95e50ea3f1fdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b87cabb1bb9427391394201b4541a02",
            "placeholder": "​",
            "style": "IPY_MODEL_002c5d77d2c0432ab85b677cb087b551",
            "value": "100%"
          }
        },
        "0c6a41b79c9e41d9afc4379002c37b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f485c70022134e87a7378767e3bd9e45",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bc82d6cf9a64f739f17ade1d5adb395",
            "value": 111898327
          }
        },
        "8588ff4af8b14fba956955babe0f4325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc19a6746dd4f1291c98ea27857a13a",
            "placeholder": "​",
            "style": "IPY_MODEL_03d28f79d3ba4cafb7157dc2a30ea6a5",
            "value": " 107M/107M [00:01&lt;00:00, 67.8MB/s]"
          }
        },
        "bcf44cc6baec464088cf2071ded9a30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b87cabb1bb9427391394201b4541a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002c5d77d2c0432ab85b677cb087b551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f485c70022134e87a7378767e3bd9e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc82d6cf9a64f739f17ade1d5adb395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc19a6746dd4f1291c98ea27857a13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d28f79d3ba4cafb7157dc2a30ea6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v4760/face_detection_neural_nets_YOLO/blob/main/Second_Submission_YOLOV8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l-tLqm2Gujh",
        "outputId": "f54eacdc-efa6-480b-c2c9-9d7869c61441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/drive/MyDrive/requirements.txt\" -q"
      ],
      "metadata": {
        "id": "5jRQayNgsMnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ad6ff6-0679-4375-80f4-a3f21bf0f293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m866.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Libraries\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.engine.results import Results\n",
        "from deepface import DeepFace\n",
        "import gradio as gr\n",
        "import shutil\n",
        "import pandas\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"✓ Libraries installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCro7UG5sMcb",
        "outputId": "631fe261-28d9-4e4c-a6b1-069c36638cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "25-10-06 12:25:51 - Directory /root/.deepface has been created\n",
            "25-10-06 12:25:51 - Directory /root/.deepface/weights has been created\n",
            "✓ Libraries installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1tY-_3p8ciP",
        "outputId": "fbc3ebad-923a-4c43-d8b7-b1ba0cb42b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM25bV93r_kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711d9942-b642-4e8e-d72f-4433be468424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 45 identity folders\n",
            "✓ images__9151_: 100 images (no augmentation needed)\n",
            "✓ images__800_: 100 images (no augmentation needed)\n",
            "✓ images__9319_: 100 images (no augmentation needed)\n",
            "✓ images__9152_: 100 images (no augmentation needed)\n",
            "✓ images__8945_: 100 images (no augmentation needed)\n",
            "✓ images__8871_: 100 images (no augmentation needed)\n",
            "✓ images__228_: 100 images (no augmentation needed)\n",
            "✓ images__7282_: 100 images (no augmentation needed)\n",
            "✓ images__3401_: 100 images (no augmentation needed)\n",
            "✓ images__3782_: 100 images (no augmentation needed)\n",
            "✓ images__3321_: 100 images (no augmentation needed)\n",
            "✓ images__2463_: 100 images (no augmentation needed)\n",
            "✓ images__3699_: 100 images (no augmentation needed)\n",
            "✓ images__10046_: 100 images (no augmentation needed)\n",
            "✓ images__6098_: 100 images (no augmentation needed)\n",
            "✓ images__3431_: 100 images (no augmentation needed)\n",
            "✓ images__487_: 100 images (no augmentation needed)\n",
            "✓ images__5239_: 100 images (no augmentation needed)\n",
            "✓ images__4304_: 100 images (no augmentation needed)\n",
            "✓ images__1852_: 100 images (no augmentation needed)\n",
            "✓ images__2837_: 100 images (no augmentation needed)\n",
            "✓ images__9256_: 100 images (no augmentation needed)\n",
            "✓ images__2522_: 100 images (no augmentation needed)\n",
            "✓ images__619_: 100 images (no augmentation needed)\n",
            "✓ images__8722_: 100 images (no augmentation needed)\n",
            "✓ images__1964_: 100 images (no augmentation needed)\n",
            "✓ images__8045_: 100 images (no augmentation needed)\n",
            "✓ images__1499_: 100 images (no augmentation needed)\n",
            "→ images__2562_: 0 images, need 100 more\n",
            "  Error: No valid images in images__2562_\n",
            "✓ images__8656_: 100 images (no augmentation needed)\n",
            "✓ images__9063_: 100 images (no augmentation needed)\n",
            "✓ images__10173_: 100 images (no augmentation needed)\n",
            "✓ images__3745_: 100 images (no augmentation needed)\n",
            "✓ images__3698_: 100 images (no augmentation needed)\n",
            "✓ images__6568_: 100 images (no augmentation needed)\n",
            "✓ images__8968_: 100 images (no augmentation needed)\n",
            "✓ images__4126_: 100 images (no augmentation needed)\n",
            "✓ images__8265_: 100 images (no augmentation needed)\n",
            "✓ images__1158_: 100 images (no augmentation needed)\n",
            "✓ images_7904_: 100 images (no augmentation needed)\n",
            "✓ images__2880_: 100 images (no augmentation needed)\n",
            "✓ images__2425_: 100 images (no augmentation needed)\n",
            "✓ images__2820_: 100 images (no augmentation needed)\n",
            "✓ images__3227_: 100 images (no augmentation needed)\n",
            "✓ images__447_: 100 images (no augmentation needed)\n",
            "\n",
            "Augmentation complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Apply random augmentation to an image\"\"\"\n",
        "    augmentations = [\n",
        "        lambda x: x.rotate(random.uniform(-15, 15), fillcolor=(0, 0, 0)),  # Random rotation\n",
        "        lambda x: ImageEnhance.Brightness(x).enhance(random.uniform(0.8, 1.2)),  # Brightness\n",
        "        lambda x: ImageEnhance.Contrast(x).enhance(random.uniform(0.8, 1.2)),  # Contrast\n",
        "        lambda x: x.transpose(Image.FLIP_LEFT_RIGHT),  # Horizontal flip\n",
        "        lambda x: ImageOps.autocontrast(x),  # Auto contrast\n",
        "        lambda x: x.rotate(random.uniform(-10, 10), fillcolor=(0, 0, 0)),  # Slight rotation\n",
        "    ]\n",
        "\n",
        "    # Apply 1-2 random augmentations\n",
        "    num_augs = random.randint(1, 2)\n",
        "    selected_augs = random.sample(augmentations, num_augs)\n",
        "\n",
        "    augmented = img.copy()\n",
        "    for aug in selected_augs:\n",
        "        augmented = aug(augmented)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "def process_identity_folders(base_folder, target_count=100):\n",
        "    \"\"\"Process each identity folder and augment to reach target count\"\"\"\n",
        "\n",
        "    # Get all subdirectories (identity folders)\n",
        "    identity_folders = [f for f in os.listdir(base_folder)\n",
        "                       if os.path.isdir(os.path.join(base_folder, f))]\n",
        "\n",
        "    print(f\"Found {len(identity_folders)} identity folders\")\n",
        "\n",
        "    for identity_folder in identity_folders:\n",
        "        folder_path = os.path.join(base_folder, identity_folder)\n",
        "\n",
        "        # Get all image files in the folder\n",
        "        image_files = [f for f in os.listdir(folder_path)\n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "        current_count = len(image_files)\n",
        "\n",
        "        if current_count >= target_count:\n",
        "            print(f\"✓ {identity_folder}: {current_count} images (no augmentation needed)\")\n",
        "            continue\n",
        "\n",
        "        needed = target_count - current_count\n",
        "        print(f\"→ {identity_folder}: {current_count} images, need {needed} more\")\n",
        "\n",
        "        # Load existing images\n",
        "        images = []\n",
        "        for img_file in image_files:\n",
        "            try:\n",
        "                img_path = os.path.join(folder_path, img_file)\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                images.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Could not load {img_file}: {e}\")\n",
        "\n",
        "        if len(images) == 0:\n",
        "            print(f\"  Error: No valid images in {identity_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Generate augmented images\n",
        "        augmented_count = 0\n",
        "        while augmented_count < needed:\n",
        "            # Randomly select a source image\n",
        "            source_img = random.choice(images)\n",
        "\n",
        "            # Augment it\n",
        "            augmented_img = augment_image(source_img)\n",
        "\n",
        "            # Save with a unique name\n",
        "            aug_filename = f\"aug_{augmented_count:04d}.jpg\"\n",
        "            aug_path = os.path.join(folder_path, aug_filename)\n",
        "\n",
        "            augmented_img.save(aug_path, quality=95)\n",
        "            augmented_count += 1\n",
        "\n",
        "        print(f\"  ✓ Generated {augmented_count} augmented images\")\n",
        "\n",
        "        # Verify final count\n",
        "        final_count = len([f for f in os.listdir(folder_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])\n",
        "        print(f\"  Final count: {final_count} images\")\n",
        "\n",
        "# Usage\n",
        "base_folder = '/content/drive/MyDrive/Celebrity Image Subsets'  # Change this to your folder path\n",
        "process_identity_folders(base_folder, target_count=100)\n",
        "print(\"\\nAugmentation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rebuild_dataset(base_folder,\n",
        "                              output_folder='/content/dataset_rebuilt',\n",
        "                              test_size=0.2,\n",
        "                              val_size=0.1,\n",
        "                              random_state=42):\n",
        "    \"\"\"Completely rebuild dataset with verified consistency\"\"\"\n",
        "\n",
        "    random.seed(random_state)\n",
        "\n",
        "    # Remove old output\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"REBUILDING DATASET WITH VERIFIED CONSISTENCY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create folders\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(output_folder, split), exist_ok=True)\n",
        "\n",
        "    # Get all identity folders - SORT CONSISTENTLY\n",
        "    identity_folders = sorted([f for f in os.listdir(base_folder)\n",
        "                              if os.path.isdir(os.path.join(base_folder, f))])\n",
        "\n",
        "    print(f\"\\nProcessing {len(identity_folders)} identities\")\n",
        "    print(f\"First 5: {identity_folders[:5]}\")\n",
        "    print(f\"Last 5: {identity_folders[-5:]}\\n\")\n",
        "\n",
        "    # Create mapping\n",
        "    import json\n",
        "    mapping = {}\n",
        "\n",
        "    # Process EACH identity with SAME class index for ALL splits\n",
        "    for class_idx, identity_folder in enumerate(identity_folders):\n",
        "        identity_path = os.path.join(base_folder, identity_folder)\n",
        "        mapping[class_idx] = identity_folder\n",
        "\n",
        "        # Get all images\n",
        "        all_images = [f for f in os.listdir(identity_path)\n",
        "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        if len(all_images) == 0:\n",
        "            print(f\"⚠️  Warning: No images in {identity_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Split images\n",
        "        train_val, test_imgs = train_test_split(\n",
        "            all_images, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        val_size_adj = val_size / (1 - test_size)\n",
        "        train_imgs, val_imgs = train_test_split(\n",
        "            train_val, test_size=val_size_adj, random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Create class folders - SAME INDEX for all splits!\n",
        "        for split, images in [('train', train_imgs), ('val', val_imgs), ('test', test_imgs)]:\n",
        "            # Use str(class_idx) for ALL splits\n",
        "            class_folder = os.path.join(output_folder, split, str(class_idx))\n",
        "            os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "            for img in images:\n",
        "                src = os.path.join(identity_path, img)\n",
        "                dst = os.path.join(class_folder, img)\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "        if (class_idx + 1) % 10 == 0:\n",
        "            print(f\"Processed {class_idx + 1}/{len(identity_folders)} identities\")\n",
        "\n",
        "    # Save mapping\n",
        "    mapping_file = os.path.join(output_folder, 'class_mapping.json')\n",
        "    with open(mapping_file, 'w') as f:\n",
        "        json.dump(mapping, f, indent=2)\n",
        "\n",
        "    # VERIFY consistency\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VERIFYING CONSISTENCY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(output_folder, split)\n",
        "        classes = sorted([f for f in os.listdir(split_path)\n",
        "                         if os.path.isdir(os.path.join(split_path, f))],\n",
        "                        key=lambda x: int(x))\n",
        "        print(f\"{split}: {len(classes)} classes ({classes[0]} to {classes[-1]})\")\n",
        "\n",
        "    # Count images\n",
        "    total_train = sum(len([f for f in os.listdir(os.path.join(output_folder, 'train', c))\n",
        "                          if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                     for c in os.listdir(os.path.join(output_folder, 'train')))\n",
        "\n",
        "    total_test = sum(len([f for f in os.listdir(os.path.join(output_folder, 'test', c))\n",
        "                         if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                    for c in os.listdir(os.path.join(output_folder, 'test')))\n",
        "\n",
        "    print(f\"\\nTotal images:\")\n",
        "    print(f\"  Train: {total_train}\")\n",
        "    print(f\"  Test: {total_test}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"✅ DATASET REBUILT: {output_folder}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return output_folder\n",
        "\n",
        "# Rebuild dataset\n",
        "base_folder = '/content/drive/MyDrive/Celebrity Image Subsets'\n",
        "new_dataset = rebuild_dataset(base_folder)"
      ],
      "metadata": {
        "id": "VK43Im9ksMhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a08a01a-f0db-4834-cf9f-422f27647270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "REBUILDING DATASET WITH VERIFIED CONSISTENCY\n",
            "======================================================================\n",
            "\n",
            "Processing 45 identities\n",
            "First 5: ['images_7904_', 'images__10046_', 'images__10173_', 'images__1158_', 'images__1499_']\n",
            "Last 5: ['images__9063_', 'images__9151_', 'images__9152_', 'images__9256_', 'images__9319_']\n",
            "\n",
            "Processed 10/45 identities\n",
            "⚠️  Warning: No images in images__2562_\n",
            "Processed 20/45 identities\n",
            "Processed 30/45 identities\n",
            "Processed 40/45 identities\n",
            "\n",
            "======================================================================\n",
            "VERIFYING CONSISTENCY\n",
            "======================================================================\n",
            "train: 44 classes (0 to 44)\n",
            "val: 44 classes (0 to 44)\n",
            "test: 44 classes (0 to 44)\n",
            "\n",
            "Total images:\n",
            "  Train: 3080\n",
            "  Test: 880\n",
            "\n",
            "======================================================================\n",
            "✅ DATASET REBUILT: /content/dataset_rebuilt\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceRecognitionSystem:\n",
        "    \"\"\"Complete face recognition system using MTCNN + FaceNet\"\"\"\n",
        "\n",
        "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Face detector (MTCNN - better than YOLO for faces)\n",
        "        self.detector = MTCNN(\n",
        "            image_size=160,\n",
        "            margin=0,\n",
        "            min_face_size=20,\n",
        "            thresholds=[0.6, 0.7, 0.7],\n",
        "            factor=0.709,\n",
        "            post_process=True,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        # Face recognizer (FaceNet)\n",
        "        self.recognizer = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n",
        "\n",
        "        # Classifier and encoder (will be trained)\n",
        "        self.classifier = None\n",
        "        self.label_encoder = None\n",
        "        self.normalizer = Normalizer(norm='l2')\n",
        "\n",
        "    def extract_face_embedding(self, image_path):\n",
        "        \"\"\"Extract face embedding from image\"\"\"\n",
        "        try:\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "            # Detect face\n",
        "            face = self.detector(img)\n",
        "\n",
        "            if face is None:\n",
        "                return None\n",
        "\n",
        "            # Get embedding\n",
        "            face = face.unsqueeze(0).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = self.recognizer(face).cpu().numpy()\n",
        "\n",
        "            return embedding.flatten()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def prepare_training_data(self, dataset_path):\n",
        "        \"\"\"Extract embeddings from training data\"\"\"\n",
        "\n",
        "        print(\"Extracting face embeddings from training data...\")\n",
        "\n",
        "        train_path = os.path.join(dataset_path, 'train')\n",
        "\n",
        "        embeddings = []\n",
        "        labels = []\n",
        "\n",
        "        # Get all class folders\n",
        "        class_folders = sorted([f for f in os.listdir(train_path)\n",
        "                               if os.path.isdir(os.path.join(train_path, f))],\n",
        "                              key=lambda x: int(x))\n",
        "\n",
        "        print(f\"Processing {len(class_folders)} classes...\\n\")\n",
        "\n",
        "        for class_idx in tqdm(class_folders, desc=\"Classes\"):\n",
        "            class_path = os.path.join(train_path, class_idx)\n",
        "\n",
        "            # Get all images\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            for img_file in images:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                # Extract embedding\n",
        "                embedding = self.extract_face_embedding(img_path)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    embeddings.append(embedding)\n",
        "                    labels.append(int(class_idx))\n",
        "\n",
        "        embeddings = np.array(embeddings)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        print(f\"\\n✓ Extracted {len(embeddings)} face embeddings\")\n",
        "        print(f\"  Embedding shape: {embeddings.shape}\")\n",
        "        print(f\"  Classes: {len(np.unique(labels))}\")\n",
        "\n",
        "        return embeddings, labels\n",
        "\n",
        "    def train_classifier(self, embeddings, labels):\n",
        "        \"\"\"Train SVM classifier on face embeddings\"\"\"\n",
        "\n",
        "        print(\"\\nTraining classifier...\")\n",
        "\n",
        "        # Normalize embeddings\n",
        "        embeddings_normalized = self.normalizer.transform(embeddings)\n",
        "\n",
        "        # Encode labels\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        labels_encoded = self.label_encoder.fit_transform(labels)\n",
        "\n",
        "        # Train SVM\n",
        "        self.classifier = SVC(\n",
        "            kernel='linear',\n",
        "            probability=True,\n",
        "            C=1.0,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.classifier.fit(embeddings_normalized, labels_encoded)\n",
        "\n",
        "        # Check training accuracy\n",
        "        train_pred = self.classifier.predict(embeddings_normalized)\n",
        "        train_acc = accuracy_score(labels_encoded, train_pred)\n",
        "\n",
        "        print(f\"✓ Classifier trained!\")\n",
        "        print(f\"  Training accuracy: {train_acc * 100:.2f}%\")\n",
        "\n",
        "        return train_acc\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"Predict identity from image\"\"\"\n",
        "\n",
        "        # Extract embedding\n",
        "        embedding = self.extract_face_embedding(image_path)\n",
        "\n",
        "        if embedding is None:\n",
        "            return None, None\n",
        "\n",
        "        # Normalize\n",
        "        embedding_normalized = self.normalizer.transform([embedding])\n",
        "\n",
        "        # Predict\n",
        "        pred_encoded = self.classifier.predict(embedding_normalized)[0]\n",
        "        pred_proba = self.classifier.predict_proba(embedding_normalized)[0]\n",
        "\n",
        "        # Decode\n",
        "        pred_class = self.label_encoder.inverse_transform([pred_encoded])[0]\n",
        "        confidence = pred_proba[pred_encoded]\n",
        "\n",
        "        return pred_class, confidence\n",
        "\n",
        "    def evaluate(self, dataset_path, split='test'):\n",
        "        \"\"\"Evaluate on test set\"\"\"\n",
        "\n",
        "        print(f\"\\nEvaluating on {split} set...\")\n",
        "\n",
        "        split_path = os.path.join(dataset_path, split)\n",
        "\n",
        "        class_folders = sorted([f for f in os.listdir(split_path)\n",
        "                               if os.path.isdir(os.path.join(split_path, f))],\n",
        "                              key=lambda x: int(x))\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for class_idx in tqdm(class_folders, desc=\"Testing\"):\n",
        "            class_path = os.path.join(split_path, class_idx)\n",
        "\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            for img_file in images:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                pred_class, confidence = self.predict(img_path)\n",
        "\n",
        "                if pred_class is not None:\n",
        "                    total += 1\n",
        "                    if pred_class == int(class_idx):\n",
        "                        correct += 1\n",
        "\n",
        "        accuracy = (correct / total * 100) if total > 0 else 0\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"{split.upper()} SET RESULTS\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Total images: {total}\")\n",
        "        print(f\"Correct: {correct}\")\n",
        "        print(f\"Accuracy: {correct}/{total} = {accuracy:.2f}%\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def save_model(self, filepath='face_recognition_model.pkl'):\n",
        "        \"\"\"Save trained classifier\"\"\"\n",
        "        model_data = {\n",
        "            'classifier': self.classifier,\n",
        "            'label_encoder': self.label_encoder,\n",
        "            'normalizer': self.normalizer\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(model_data, f)\n",
        "\n",
        "        print(f\"✓ Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath='face_recognition_model.pkl'):\n",
        "        \"\"\"Load trained classifier\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        self.classifier = model_data['classifier']\n",
        "        self.label_encoder = model_data['label_encoder']\n",
        "        self.normalizer = model_data['normalizer']\n",
        "\n",
        "        print(f\"✓ Model loaded from {filepath}\")\n",
        "\n",
        "# Initialize system\n",
        "print(\"=\"*70)\n",
        "print(\"INITIALIZING FACE RECOGNITION SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "face_system = FaceRecognitionSystem()"
      ],
      "metadata": {
        "id": "-gzSrP6VsMZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "9a462d3ccc3b42dbae35c7539d82b3f2",
            "0dac5344f25b46c99c95e50ea3f1fdf2",
            "0c6a41b79c9e41d9afc4379002c37b17",
            "8588ff4af8b14fba956955babe0f4325",
            "bcf44cc6baec464088cf2071ded9a30f",
            "1b87cabb1bb9427391394201b4541a02",
            "002c5d77d2c0432ab85b677cb087b551",
            "f485c70022134e87a7378767e3bd9e45",
            "9bc82d6cf9a64f739f17ade1d5adb395",
            "ccc19a6746dd4f1291c98ea27857a13a",
            "03d28f79d3ba4cafb7157dc2a30ea6a5"
          ]
        },
        "outputId": "ea6ff3d5-7d75-469a-9a14-ee621547cd2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "INITIALIZING FACE RECOGNITION SYSTEM\n",
            "======================================================================\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a462d3ccc3b42dbae35c7539d82b3f2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING AND TESTING THE MODEL WITH SINGLE IMAGES"
      ],
      "metadata": {
        "id": "uzKZ_4wkyJtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path\n",
        "dataset_path = '/content/dataset_rebuilt'  # Use your correct dataset\n",
        "\n",
        "# Step 1: Extract embeddings from training data\n",
        "embeddings, labels = face_system.prepare_training_data(dataset_path)\n",
        "\n",
        "# Step 2: Train classifier\n",
        "train_accuracy = face_system.train_classifier(embeddings, labels)\n",
        "\n",
        "# Step 3: Evaluate on test set\n",
        "test_accuracy = face_system.evaluate(dataset_path, split='test')\n",
        "\n",
        "# Step 4: Save model\n",
        "face_system.save_model('/content/face_recognition_facenet.pkl')"
      ],
      "metadata": {
        "id": "xRhBP4hPsMWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de1a878-38f7-47a6-adf3-da7084ea2f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting face embeddings from training data...\n",
            "Processing 44 classes...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classes: 100%|██████████| 44/44 [02:20<00:00,  3.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Extracted 3078 face embeddings\n",
            "  Embedding shape: (3078, 512)\n",
            "  Classes: 44\n",
            "\n",
            "Training classifier...\n",
            "✓ Classifier trained!\n",
            "  Training accuracy: 99.84%\n",
            "\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 44/44 [00:47<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Total images: 880\n",
            "Correct: 879\n",
            "Accuracy: 879/880 = 99.89%\n",
            "======================================================================\n",
            "✓ Model saved to /content/face_recognition_facenet.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTING 2X2 COLLAGES"
      ],
      "metadata": {
        "id": "MugxH40qyOi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_collages(test_folder='/content/dataset_rebuilt/test',\n",
        "                        num_collages=50,\n",
        "                        output_folder='/content/test_collages'):\n",
        "    \"\"\"Create collages for testing face recognition\"\"\"\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get all class folders\n",
        "    class_folders = sorted([f for f in os.listdir(test_folder)\n",
        "                           if os.path.isdir(os.path.join(test_folder, f))],\n",
        "                          key=lambda x: int(x))\n",
        "\n",
        "    print(f\"Creating {num_collages} test collages from {len(class_folders)} classes...\\n\")\n",
        "\n",
        "    for collage_num in range(num_collages):\n",
        "        # Randomly select 4 different classes\n",
        "        selected_classes = random.sample(class_folders, 4)\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for class_idx in selected_classes:\n",
        "            class_path = os.path.join(test_folder, class_idx)\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            if not image_files:\n",
        "                continue\n",
        "\n",
        "            # Pick random image\n",
        "            random_image = random.choice(image_files)\n",
        "            img_path = os.path.join(class_path, random_image)\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            images.append(img)\n",
        "            labels.append(int(class_idx))\n",
        "\n",
        "        if len(images) < 4:\n",
        "            continue\n",
        "\n",
        "        # Resize to same size\n",
        "        min_width = min(img.width for img in images)\n",
        "        min_height = min(img.height for img in images)\n",
        "        resized_images = [img.resize((min_width, min_height), Image.LANCZOS)\n",
        "                         for img in images]\n",
        "\n",
        "        # Create 2x2 grid\n",
        "        img_arrays = [np.asarray(img) for img in resized_images]\n",
        "        top_row = np.hstack([img_arrays[0], img_arrays[1]])\n",
        "        bottom_row = np.hstack([img_arrays[2], img_arrays[3]])\n",
        "        collage = np.vstack([top_row, bottom_row])\n",
        "\n",
        "        # Save collage\n",
        "        collage_img = Image.fromarray(collage.astype('uint8'))\n",
        "        output_path = os.path.join(output_folder, f'collage_{collage_num + 1:03d}.jpg')\n",
        "        collage_img.save(output_path, quality=95)\n",
        "\n",
        "        # Save ground truth labels\n",
        "        labels_path = os.path.join(output_folder, f'collage_{collage_num + 1:03d}_labels.txt')\n",
        "        with open(labels_path, 'w') as f:\n",
        "            f.write(f\"Top-left: Class {labels[0]}\\n\")\n",
        "            f.write(f\"Top-right: Class {labels[1]}\\n\")\n",
        "            f.write(f\"Bottom-left: Class {labels[2]}\\n\")\n",
        "            f.write(f\"Bottom-right: Class {labels[3]}\\n\")\n",
        "\n",
        "        if (collage_num + 1) % 10 == 0:\n",
        "            print(f\"Created {collage_num + 1}/{num_collages} collages...\")\n",
        "\n",
        "    print(f\"\\n✓ Created {num_collages} collages in '{output_folder}'\")\n",
        "\n",
        "# Create collages\n",
        "create_test_collages('/content/dataset_rebuilt/test',\n",
        "                    num_collages=50,\n",
        "                    output_folder='/content/test_collages')"
      ],
      "metadata": {
        "id": "ruU5t05xyUjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20bdada-3b68-436b-d534-ed0c1951b0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 50 test collages from 44 classes...\n",
            "\n",
            "Created 10/50 collages...\n",
            "Created 20/50 collages...\n",
            "Created 30/50 collages...\n",
            "Created 40/50 collages...\n",
            "Created 50/50 collages...\n",
            "\n",
            "✓ Created 50 collages in '/content/test_collages'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_collages_facenet(face_system, collage_folder='/content/test_collages'):\n",
        "    \"\"\"Evaluate FaceNet system on collages\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING ON COLLAGES (FaceNet)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    collage_files = sorted([f for f in os.listdir(collage_folder)\n",
        "                           if f.endswith('.jpg') and f.startswith('collage_')])\n",
        "\n",
        "    total_faces = 0\n",
        "    correct_faces = 0\n",
        "\n",
        "    for collage_file in collage_files:\n",
        "        collage_path = os.path.join(collage_folder, collage_file)\n",
        "        labels_path = collage_path.replace('.jpg', '_labels.txt')\n",
        "\n",
        "        # Parse ground truth labels\n",
        "        with open(labels_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        true_classes = []\n",
        "        for line in lines:\n",
        "            match = re.search(r'Class (\\d+)', line)\n",
        "            if match:\n",
        "                true_classes.append(int(match.group(1)))\n",
        "\n",
        "        # Split collage into 4 quadrants\n",
        "        img = Image.open(collage_path)\n",
        "        width, height = img.size\n",
        "        half_w = width // 2\n",
        "        half_h = height // 2\n",
        "\n",
        "        positions = [\n",
        "            (0, 0, half_w, half_h),\n",
        "            (half_w, 0, width, half_h),\n",
        "            (0, half_h, half_w, height),\n",
        "            (half_w, half_h, width, height)\n",
        "        ]\n",
        "\n",
        "        # Predict each face\n",
        "        for i, (left, top, right, bottom) in enumerate(positions):\n",
        "            if i >= len(true_classes):\n",
        "                break\n",
        "\n",
        "            # Crop face\n",
        "            face_crop = img.crop((left, top, right, bottom))\n",
        "            temp_path = f'/content/temp_collage_face_{i}.jpg'\n",
        "            face_crop.save(temp_path)\n",
        "\n",
        "            # Predict\n",
        "            pred_class, confidence = face_system.predict(temp_path)\n",
        "\n",
        "            if pred_class is not None:\n",
        "                total_faces += 1\n",
        "                if pred_class == true_classes[i]:\n",
        "                    correct_faces += 1\n",
        "\n",
        "        if (collage_files.index(collage_file) + 1) % 10 == 0:\n",
        "            print(f\"Processed {collage_files.index(collage_file) + 1}/{len(collage_files)} collages...\")\n",
        "\n",
        "    accuracy = (correct_faces / total_faces * 100) if total_faces > 0 else 0\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"COLLAGE RESULTS (FaceNet)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total faces: {total_faces}\")\n",
        "    print(f\"Correct: {correct_faces}\")\n",
        "    print(f\"🎯 Accuracy: {correct_faces}/{total_faces} = {accuracy:.2f}%\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on collages\n",
        "collage_acc = evaluate_collages_facenet(face_system, '/content/test_collages')"
      ],
      "metadata": {
        "id": "zsPv4BhMsMTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba66aaf-ee2d-4f33-d002-e20993df3ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING ON COLLAGES (FaceNet)\n",
            "======================================================================\n",
            "Processed 10/50 collages...\n",
            "Processed 20/50 collages...\n",
            "Processed 30/50 collages...\n",
            "Processed 40/50 collages...\n",
            "Processed 50/50 collages...\n",
            "\n",
            "======================================================================\n",
            "COLLAGE RESULTS (FaceNet)\n",
            "======================================================================\n",
            "Total faces: 198\n",
            "Correct: 198\n",
            "🎯 Accuracy: 198/198 = 100.00%\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GrDgB78Qx0in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3X3 collage testing"
      ],
      "metadata": {
        "id": "ZBgYjC0qx2td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_3x3_collages(dataset_path,\n",
        "                       num_collages=100,\n",
        "                       split='test',\n",
        "                       output_folder='/content/collages_3x3'):\n",
        "    \"\"\"Create 3x3 collages with 9 random faces\n",
        "\n",
        "    Args:\n",
        "        dataset_path: Path to dataset (e.g., '/content/dataset_rebuilt')\n",
        "        num_collages: Number of collages to create\n",
        "        split: Which split to use ('train', 'val', or 'test')\n",
        "        output_folder: Where to save collages\n",
        "    \"\"\"\n",
        "\n",
        "    source_dir = os.path.join(dataset_path, split)\n",
        "\n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"❌ Source folder not found: {source_dir}\")\n",
        "        return None\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get all class folders\n",
        "    class_folders = sorted([f for f in os.listdir(source_dir)\n",
        "                           if os.path.isdir(os.path.join(source_dir, f))],\n",
        "                          key=lambda x: int(x))\n",
        "\n",
        "    if len(class_folders) < 9:\n",
        "        print(f\"❌ Need at least 9 classes, found only {len(class_folders)}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Creating {num_collages} 3x3 collages from {len(class_folders)} classes...\")\n",
        "    print(f\"Using images from: {split} set\\n\")\n",
        "\n",
        "    created_count = 0\n",
        "\n",
        "    for collage_num in range(num_collages):\n",
        "        # Randomly select 9 different classes\n",
        "        selected_classes = random.sample(class_folders, 9)\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        # Get one random image from each selected class\n",
        "        for class_idx in selected_classes:\n",
        "            class_path = os.path.join(source_dir, class_idx)\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            if not image_files:\n",
        "                continue\n",
        "\n",
        "            # Pick random image\n",
        "            random_image = random.choice(image_files)\n",
        "            img_path = os.path.join(class_path, random_image)\n",
        "\n",
        "            try:\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                images.append(img)\n",
        "                labels.append(int(class_idx))\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if len(images) < 9:\n",
        "            print(f\"⚠️  Skipping collage {collage_num + 1} - only {len(images)} valid images\")\n",
        "            continue\n",
        "\n",
        "        # Resize all images to same size\n",
        "        min_width = min(img.width for img in images)\n",
        "        min_height = min(img.height for img in images)\n",
        "        resized_images = [img.resize((min_width, min_height), Image.LANCZOS)\n",
        "                         for img in images]\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        img_arrays = [np.asarray(img) for img in resized_images]\n",
        "\n",
        "        # Create 3x3 grid\n",
        "        # Row 1: images 0, 1, 2\n",
        "        row1 = np.hstack([img_arrays[0], img_arrays[1], img_arrays[2]])\n",
        "        # Row 2: images 3, 4, 5\n",
        "        row2 = np.hstack([img_arrays[3], img_arrays[4], img_arrays[5]])\n",
        "        # Row 3: images 6, 7, 8\n",
        "        row3 = np.hstack([img_arrays[6], img_arrays[7], img_arrays[8]])\n",
        "\n",
        "        # Stack all rows vertically\n",
        "        collage = np.vstack([row1, row2, row3])\n",
        "\n",
        "        # Save collage\n",
        "        collage_img = Image.fromarray(collage.astype('uint8'))\n",
        "        output_path = os.path.join(output_folder, f'collage_3x3_{collage_num + 1:03d}.jpg')\n",
        "        collage_img.save(output_path, quality=95)\n",
        "\n",
        "        # Save labels (positions in grid)\n",
        "        labels_path = os.path.join(output_folder, f'collage_3x3_{collage_num + 1:03d}_labels.txt')\n",
        "        with open(labels_path, 'w') as f:\n",
        "            f.write(f\"Top-left: Class {labels[0]}\\n\")\n",
        "            f.write(f\"Top-center: Class {labels[1]}\\n\")\n",
        "            f.write(f\"Top-right: Class {labels[2]}\\n\")\n",
        "            f.write(f\"Middle-left: Class {labels[3]}\\n\")\n",
        "            f.write(f\"Middle-center: Class {labels[4]}\\n\")\n",
        "            f.write(f\"Middle-right: Class {labels[5]}\\n\")\n",
        "            f.write(f\"Bottom-left: Class {labels[6]}\\n\")\n",
        "            f.write(f\"Bottom-center: Class {labels[7]}\\n\")\n",
        "            f.write(f\"Bottom-right: Class {labels[8]}\\n\")\n",
        "\n",
        "        created_count += 1\n",
        "\n",
        "        if created_count % 20 == 0:\n",
        "            print(f\"Created {created_count}/{num_collages} collages...\")\n",
        "\n",
        "    print(f\"\\n✓ Created {created_count} 3x3 collages in '{output_folder}'\")\n",
        "    return output_folder\n",
        "\n",
        "# Create 100 3x3 test collages\n",
        "collage_folder_3x3 = create_3x3_collages(\n",
        "    dataset_path='/content/dataset_rebuilt',\n",
        "    num_collages=100,\n",
        "    split='test',\n",
        "    output_folder='/content/collages_3x3_test'\n",
        ")"
      ],
      "metadata": {
        "id": "Ds-sLclYx0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68f9f6c-a8b1-4ca9-e437-165e135493c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 100 3x3 collages from 44 classes...\n",
            "Using images from: test set\n",
            "\n",
            "Created 20/100 collages...\n",
            "Created 40/100 collages...\n",
            "Created 60/100 collages...\n",
            "Created 80/100 collages...\n",
            "Created 100/100 collages...\n",
            "\n",
            "✓ Created 100 3x3 collages in '/content/collages_3x3_test'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_3x3_collages_facenet(face_system, collage_folder='/content/collages_3x3_test'):\n",
        "    \"\"\"Evaluate FaceNet on 3x3 collages\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING ON 3x3 COLLAGES (9 Faces)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    collage_files = sorted([f for f in os.listdir(collage_folder)\n",
        "                           if f.endswith('.jpg') and 'collage_3x3' in f])\n",
        "\n",
        "    if not collage_files:\n",
        "        print(f\"❌ No collages found in {collage_folder}\")\n",
        "        return 0\n",
        "\n",
        "    print(f\"Found {len(collage_files)} collages\\n\")\n",
        "\n",
        "    total_faces = 0\n",
        "    correct_faces = 0\n",
        "\n",
        "    for collage_file in collage_files:\n",
        "        collage_path = os.path.join(collage_folder, collage_file)\n",
        "        labels_path = collage_path.replace('.jpg', '_labels.txt')\n",
        "\n",
        "        if not os.path.exists(labels_path):\n",
        "            print(f\"⚠️  No labels for {collage_file}\")\n",
        "            continue\n",
        "\n",
        "        # Parse ground truth labels\n",
        "        with open(labels_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        true_classes = []\n",
        "        for line in lines:\n",
        "            match = re.search(r'Class (\\d+)', line)\n",
        "            if match:\n",
        "                true_classes.append(int(match.group(1)))\n",
        "\n",
        "        if len(true_classes) != 9:\n",
        "            print(f\"⚠️  Expected 9 labels, got {len(true_classes)} for {collage_file}\")\n",
        "            continue\n",
        "\n",
        "        # Load and split collage into 3x3 grid\n",
        "        img = Image.open(collage_path)\n",
        "        width, height = img.size\n",
        "\n",
        "        cell_width = width // 3\n",
        "        cell_height = height // 3\n",
        "\n",
        "        # Define 9 positions (3x3 grid)\n",
        "        positions = []\n",
        "        for row in range(3):\n",
        "            for col in range(3):\n",
        "                left = col * cell_width\n",
        "                top = row * cell_height\n",
        "                right = left + cell_width\n",
        "                bottom = top + cell_height\n",
        "                positions.append((left, top, right, bottom))\n",
        "\n",
        "        # Predict each face\n",
        "        for i, (left, top, right, bottom) in enumerate(positions):\n",
        "            # Crop face\n",
        "            face_crop = img.crop((left, top, right, bottom))\n",
        "            temp_path = f'/content/temp_3x3_face_{i}.jpg'\n",
        "            face_crop.save(temp_path)\n",
        "\n",
        "            # Predict\n",
        "            pred_class, confidence = face_system.predict(temp_path)\n",
        "\n",
        "            if pred_class is not None:\n",
        "                total_faces += 1\n",
        "                if pred_class == true_classes[i]:\n",
        "                    correct_faces += 1\n",
        "\n",
        "        if (collage_files.index(collage_file) + 1) % 20 == 0:\n",
        "            print(f\"Processed {collage_files.index(collage_file) + 1}/{len(collage_files)} collages...\")\n",
        "\n",
        "    accuracy = (correct_faces / total_faces * 100) if total_faces > 0 else 0\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"3x3 COLLAGE RESULTS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total collages: {len(collage_files)}\")\n",
        "    print(f\"Total faces: {total_faces}\")\n",
        "    print(f\"Correct predictions: {correct_faces}\")\n",
        "    print(f\"Incorrect predictions: {total_faces - correct_faces}\")\n",
        "    print(f\"\\n🎯 Accuracy: {correct_faces}/{total_faces} = {accuracy:.2f}%\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on 3x3 collages\n",
        "if os.path.exists('/content/collages_3x3_test'):\n",
        "    collage_3x3_acc = evaluate_3x3_collages_facenet(face_system, '/content/collages_3x3_test')"
      ],
      "metadata": {
        "id": "jkhBFjekx0c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768c30b5-7904-42cc-8893-0b6a124e658f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING ON 3x3 COLLAGES (9 Faces)\n",
            "======================================================================\n",
            "Found 100 collages\n",
            "\n",
            "Processed 20/100 collages...\n",
            "Processed 40/100 collages...\n",
            "Processed 60/100 collages...\n",
            "Processed 80/100 collages...\n",
            "Processed 100/100 collages...\n",
            "\n",
            "======================================================================\n",
            "3x3 COLLAGE RESULTS\n",
            "======================================================================\n",
            "Total collages: 100\n",
            "Total faces: 891\n",
            "Correct predictions: 890\n",
            "Incorrect predictions: 1\n",
            "\n",
            "🎯 Accuracy: 890/891 = 99.89%\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVING the model in DRIVE"
      ],
      "metadata": {
        "id": "WhpWwUCayAh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def save_complete_progress(backup_name=None):\n",
        "    \"\"\"Save all progress to Google Drive\"\"\"\n",
        "\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create backup folder with timestamp\n",
        "    if backup_name is None:\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        backup_name = f'face_recognition_backup_{timestamp}'\n",
        "\n",
        "    backup_root = f'/content/drive/MyDrive/{backup_name}'\n",
        "    os.makedirs(backup_root, exist_ok=True)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"SAVING COMPLETE PROGRESS TO GOOGLE DRIVE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Backup location: {backup_root}\\n\")\n",
        "\n",
        "    saved_items = []\n",
        "\n",
        "    # 1. Save FaceNet model\n",
        "    print(\"1. Saving FaceNet model...\")\n",
        "    if os.path.exists('/content/face_recognition_facenet.pkl'):\n",
        "        shutil.copy2('/content/face_recognition_facenet.pkl',\n",
        "                    f'{backup_root}/face_recognition_facenet.pkl')\n",
        "        print(\"   ✓ FaceNet model saved\")\n",
        "        saved_items.append('FaceNet model')\n",
        "    else:\n",
        "        print(\"   ⚠️  FaceNet model not found\")\n",
        "\n",
        "    # 2. Save dataset\n",
        "    print(\"\\n2. Saving dataset...\")\n",
        "    dataset_paths = [\n",
        "        '/content/dataset_rebuilt',\n",
        "        '/content/dataset_yolo_final',\n",
        "        '/content/face_recognition_dataset'\n",
        "    ]\n",
        "\n",
        "    dataset_saved = False\n",
        "    for dataset_path in dataset_paths:\n",
        "        if os.path.exists(dataset_path):\n",
        "            dataset_name = os.path.basename(dataset_path)\n",
        "            dest = f'{backup_root}/{dataset_name}'\n",
        "\n",
        "            print(f\"   Copying {dataset_name}...\")\n",
        "            if os.path.exists(dest):\n",
        "                shutil.rmtree(dest)\n",
        "            shutil.copytree(dataset_path, dest)\n",
        "\n",
        "            # Get size\n",
        "            size = sum(os.path.getsize(os.path.join(dirpath, filename))\n",
        "                      for dirpath, dirnames, filenames in os.walk(dest)\n",
        "                      for filename in filenames)\n",
        "            size_mb = size / (1024 * 1024)\n",
        "\n",
        "            print(f\"   ✓ Dataset saved: {dataset_name} ({size_mb:.2f} MB)\")\n",
        "            saved_items.append(f'Dataset ({dataset_name})')\n",
        "            dataset_saved = True\n",
        "            break\n",
        "\n",
        "    if not dataset_saved:\n",
        "        print(\"   ⚠️  No dataset found\")\n",
        "\n",
        "    # 3. Save all collages\n",
        "    print(\"\\n3. Saving collages...\")\n",
        "    collage_folders = [\n",
        "        '/content/collages_3x3',\n",
        "        '/content/collages_2x2',\n",
        "        '/content/collages_4x4',\n",
        "        '/content/test_collages',\n",
        "        '/content/collages'\n",
        "    ]\n",
        "\n",
        "    collage_count = 0\n",
        "    for collage_folder in collage_folders:\n",
        "        if os.path.exists(collage_folder):\n",
        "            folder_name = os.path.basename(collage_folder)\n",
        "            dest = f'{backup_root}/collages/{folder_name}'\n",
        "\n",
        "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
        "            if os.path.exists(dest):\n",
        "                shutil.rmtree(dest)\n",
        "            shutil.copytree(collage_folder, dest)\n",
        "\n",
        "            num_collages = len([f for f in os.listdir(dest) if f.endswith('.jpg')])\n",
        "            print(f\"   ✓ Saved {folder_name}: {num_collages} collages\")\n",
        "            collage_count += num_collages\n",
        "\n",
        "    if collage_count > 0:\n",
        "        saved_items.append(f'Collages ({collage_count} total)')\n",
        "    else:\n",
        "        print(\"   ⚠️  No collages found\")\n",
        "\n",
        "    # 4. Save class mapping\n",
        "    print(\"\\n4. Saving class mapping...\")\n",
        "    mapping_files = [\n",
        "        '/content/dataset_rebuilt/class_mapping.json',\n",
        "        '/content/dataset_yolo_final/class_mapping.json',\n",
        "        '/content/identity_mapping.json'\n",
        "    ]\n",
        "\n",
        "    for mapping_file in mapping_files:\n",
        "        if os.path.exists(mapping_file):\n",
        "            filename = os.path.basename(mapping_file)\n",
        "            shutil.copy2(mapping_file, f'{backup_root}/{filename}')\n",
        "            print(f\"   ✓ Saved {filename}\")\n",
        "            saved_items.append('Class mapping')\n",
        "            break\n",
        "\n",
        "    # 5. Save training results (if from YOLO)\n",
        "    print(\"\\n5. Saving training results...\")\n",
        "    if os.path.exists('runs'):\n",
        "        dest = f'{backup_root}/training_runs'\n",
        "        if os.path.exists(dest):\n",
        "            shutil.rmtree(dest)\n",
        "        shutil.copytree('runs', dest)\n",
        "        print(\"   ✓ Training runs saved\")\n",
        "        saved_items.append('Training results')\n",
        "\n",
        "    # 6. Save metadata\n",
        "    print(\"\\n6. Saving metadata...\")\n",
        "    metadata = {\n",
        "        'backup_date': datetime.now().isoformat(),\n",
        "        'saved_items': saved_items,\n",
        "        'python_version': '3.12',\n",
        "        'libraries': {\n",
        "            'facenet_pytorch': 'installed',\n",
        "            'ultralytics': 'installed',\n",
        "            'torch': 'installed'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(f'{backup_root}/backup_metadata.json', 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    print(\"   ✓ Metadata saved\")\n",
        "\n",
        "    # 7. Save restore instructions\n",
        "    restore_instructions = f\"\"\"\n",
        "# ========================================\n",
        "# RESTORE INSTRUCTIONS\n",
        "# ========================================\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Run the restore script (see restore_progress.py)\n",
        "# Or manually copy files:\n",
        "\n",
        "# Restore dataset:\n",
        "import shutil\n",
        "shutil.copytree('{backup_root}/dataset_rebuilt', '/content/dataset_rebuilt')\n",
        "\n",
        "# Restore model:\n",
        "shutil.copy2('{backup_root}/face_recognition_facenet.pkl',\n",
        "             '/content/face_recognition_facenet.pkl')\n",
        "\n",
        "# Restore collages:\n",
        "shutil.copytree('{backup_root}/collages', '/content')\n",
        "\n",
        "# 3. Load the model:\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import pickle\n",
        "\n",
        "# Load saved model\n",
        "with open('/content/face_recognition_facenet.pkl', 'rb') as f:\n",
        "    model_data = pickle.load(f)\n",
        "\n",
        "# Reinitialize FaceRecognitionSystem and load weights\n",
        "face_system = FaceRecognitionSystem()\n",
        "face_system.classifier = model_data['classifier']\n",
        "face_system.label_encoder = model_data['label_encoder']\n",
        "face_system.normalizer = model_data['normalizer']\n",
        "\n",
        "print(\"✓ Ready to continue!\")\n",
        "\"\"\"\n",
        "\n",
        "    with open(f'{backup_root}/RESTORE_INSTRUCTIONS.txt', 'w') as f:\n",
        "        f.write(restore_instructions)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BACKUP COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Location: {backup_root}\")\n",
        "    print(f\"\\nSaved items:\")\n",
        "    for item in saved_items:\n",
        "        print(f\"  • {item}\")\n",
        "    print(f\"\\nTo restore, see: {backup_root}/RESTORE_INSTRUCTIONS.txt\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return backup_root\n",
        "\n",
        "# Save everything\n",
        "backup_location = save_complete_progress()"
      ],
      "metadata": {
        "id": "DM-00kbpx0YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529be7f9-9189-4895-d0f2-208c378d6c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "======================================================================\n",
            "SAVING COMPLETE PROGRESS TO GOOGLE DRIVE\n",
            "======================================================================\n",
            "Backup location: /content/drive/MyDrive/face_recognition_backup_20251006_011813\n",
            "\n",
            "1. Saving FaceNet model...\n",
            "   ✓ FaceNet model saved\n",
            "\n",
            "2. Saving dataset...\n",
            "   Copying dataset_rebuilt...\n",
            "   ✓ Dataset saved: dataset_rebuilt (56.35 MB)\n",
            "\n",
            "3. Saving collages...\n",
            "   ✓ Saved test_collages: 50 collages\n",
            "\n",
            "4. Saving class mapping...\n",
            "   ✓ Saved class_mapping.json\n",
            "\n",
            "5. Saving training results...\n",
            "\n",
            "6. Saving metadata...\n",
            "   ✓ Metadata saved\n",
            "\n",
            "======================================================================\n",
            "BACKUP COMPLETE!\n",
            "======================================================================\n",
            "Location: /content/drive/MyDrive/face_recognition_backup_20251006_011813\n",
            "\n",
            "Saved items:\n",
            "  • FaceNet model\n",
            "  • Dataset (dataset_rebuilt)\n",
            "  • Collages (50 total)\n",
            "  • Class mapping\n",
            "\n",
            "To restore, see: /content/drive/MyDrive/face_recognition_backup_20251006_011813/RESTORE_INSTRUCTIONS.txt\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}